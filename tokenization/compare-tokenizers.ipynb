{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split on whitespace 99 tokens\n",
      "----------------------------------------------------------------------------------------------------\n",
      "297 tokens\n",
      "----------------------------------------------------------------------------------------------------\n",
      "▁We ▁a im ed ▁to ▁evaluate ▁the ▁effect ▁of ▁sleep ▁quality ▁on ▁memory , ▁ex ec ut ive ▁function , ▁and ▁language ▁performance ▁in ▁patients ▁with ▁re frac t ory ▁fo cal ▁epi le p s y ▁and ▁control led ▁epi le p s y ▁and ▁comp are ▁these </s> ▁with ▁health y ▁individual s . ▁We ▁pro spec t ive ly ▁en roll ed ▁ 37 ▁ ado les cent ▁and ▁adult ▁patients ▁with ▁re frac t ory ▁fo cal ▁epi le p s y . </s> </s> ▁How ▁to ▁avoid ▁anti - c lock wise ▁ro t ation ▁an im ation ▁when ▁re set ing ▁ro t ation ▁from ▁3 60 de g ▁to ▁0 ▁de g ? </s> </s> ▁I ▁am ▁cre ating ▁an ▁an im ation ▁that ▁look s ▁like ▁a ▁f ancy ▁wh e el , ▁When ▁re set ting ▁ro t ation ▁from ▁3 60 de g ▁to ▁0 ▁de g , ▁It ▁an im ating ▁the ▁wh e el ▁in ▁anti - c lock wise ▁direction , ▁How ▁to ▁A vo id ▁this ? ? ? </s> ▁H T M L </s> ▁< ul ▁class =\" cm \"> </s> ▁< li >< span > 01 </ span ></ li > </s> ▁< li >< span > 02 </ span ></ li > </s> ▁< li >< span > 03 </ span ></ li > </s> ▁< li >< span > 04 </ span ></ li > </s> ▁< li >< span > 05 </ span ></ li > </s> ▁< li >< span > 06 </ span ></ li > </s> ▁< li >< span > 07 </ span ></ li > </s> ▁< li >< span > 08 </ span ></ li > </s> </s> ▁</ ul > </s>\n",
      "----------------------------------------------------------------------------------------------------\n",
      "268 tokens\n",
      "----------------------------------------------------------------------------------------------------\n",
      "▁We ▁aim ed ▁to ▁evaluate ▁the ▁effect ▁of ▁sleep ▁quality ▁on ▁memory , ▁executive ▁function , ▁and ▁language ▁performance ▁in ▁patients ▁with ▁re frac tory ▁fo cal ▁epi le p s y ▁and ▁controlled ▁epi le p s y ▁and ▁compare ▁these </s> ▁with ▁healthy ▁individuals . ▁We ▁prospect ive ly ▁en roll ed ▁37 ▁ ado les cent ▁and ▁adult ▁patients ▁with ▁re frac tory ▁fo cal ▁epi le p s y . </s> </s> ▁How ▁to ▁avoid ▁anti - c lock wise ▁rotation ▁ anim ation ▁when ▁re set ing ▁rotation ▁from ▁3 60 de g ▁to ▁0 ▁de g ? </s> </s> ▁I ▁am ▁creating ▁an ▁ anim ation ▁that ▁looks ▁like ▁a ▁f ancy ▁wheel , ▁When ▁res etting ▁rotation ▁from ▁3 60 de g ▁to ▁0 ▁de g , ▁It ▁ anim ating ▁the ▁wheel ▁in ▁anti - c lock wise ▁direction , ▁How ▁to ▁A void ▁this ? ? ? </s> ▁ HTML </s> ▁< ul ▁class =\" cm \"> </s> ▁< li >< span > 01 </ span ></ li > </s> ▁< li >< span > 02 </ span ></ li > </s> ▁< li >< span > 03 </ span ></ li > </s> ▁< li >< span > 04 </ span ></ li > </s> ▁< li >< span > 05 </ span ></ li > </s> ▁< li >< span > 06 </ span ></ li > </s> ▁< li >< span > 07 </ span ></ li > </s> ▁< li >< span > 08 </ span ></ li > </s> </s> ▁</ ul > </s>\n",
      "----------------------------------------------------------------------------------------------------\n",
      "242 tokens\n",
      "----------------------------------------------------------------------------------------------------\n",
      "▁We ▁aimed ▁to ▁evaluate ▁the ▁effect ▁of ▁sleep ▁quality ▁on ▁memory , ▁executive ▁function , ▁and ▁language ▁performance ▁in ▁patients ▁with ▁re frac tory ▁focal ▁epi le psy ▁and ▁controlled ▁epi le psy ▁and ▁compare ▁these </s> ▁with ▁healthy ▁individuals . ▁We ▁prospective ly ▁enrolled ▁37 ▁adolescent ▁and ▁adult ▁patients ▁with ▁re frac tory ▁focal ▁epi le psy . </s> </s> ▁How ▁to ▁avoid ▁anti - clock wise ▁rotation ▁animation ▁when ▁reset ing ▁rotation ▁from ▁ 360 de g ▁to ▁0 ▁de g ? </s> </s> ▁I ▁am ▁creating ▁an ▁animation ▁that ▁looks ▁like ▁a ▁fancy ▁wheel , ▁When ▁reset ting ▁rotation ▁from ▁ 360 de g ▁to ▁0 ▁de g , ▁It ▁ anim ating ▁the ▁wheel ▁in ▁anti - clock wise ▁direction , ▁How ▁to ▁A void ▁this ??? </s> ▁HTML </s> ▁< ul ▁class =\" cm \"> </s> ▁< li >< span > 01 </ span ></ li > </s> ▁< li >< span > 02 </ span ></ li > </s> ▁< li >< span > 03 </ span ></ li > </s> ▁< li >< span > 04 </ span ></ li > </s> ▁< li >< span > 05 </ span ></ li > </s> ▁< li >< span > 06 </ span ></ li > </s> ▁< li >< span > 07 </ span ></ li > </s> ▁< li >< span > 08 </ span ></ li > </s> </s> ▁</ ul > </s>\n",
      "----------------------------------------------------------------------------------------------------\n",
      "225 tokens\n",
      "----------------------------------------------------------------------------------------------------\n",
      "▁We ▁aimed ▁to ▁evaluate ▁the ▁effect ▁of ▁sleep ▁quality ▁on ▁memory , ▁executive ▁function , ▁and ▁language ▁performance ▁in ▁patients ▁with ▁refractory ▁focal ▁epilepsy ▁and ▁controlled ▁epilepsy ▁and ▁compare ▁these </s> ▁with ▁healthy ▁individuals . ▁We ▁prospective ly ▁enrolled ▁37 ▁adolescent ▁and ▁adult ▁patients ▁with ▁refractory ▁focal ▁epilepsy . </s> </s> ▁How ▁to ▁avoid ▁anti - clockwise ▁rotation ▁animation ▁when ▁reset ing ▁rotation ▁from ▁360 deg ▁to ▁0 ▁de g ? </s> </s> ▁I ▁am ▁creating ▁an ▁animation ▁that ▁looks ▁like ▁a ▁fancy ▁wheel , ▁When ▁re setting ▁rotation ▁from ▁360 deg ▁to ▁0 ▁de g , ▁It ▁ anim ating ▁the ▁wheel ▁in ▁anti - clockwise ▁direction , ▁How ▁to ▁Avoid ▁this ??? </s> ▁HTML </s> ▁< ul ▁class =\" cm \"> </s> ▁< li >< span > 01 </ span ></ li > </s> ▁< li >< span > 02 </ span ></ li > </s> ▁< li >< span > 03 </ span ></ li > </s> ▁< li >< span > 04 </ span ></ li > </s> ▁< li >< span > 05 </ span ></ li > </s> ▁< li >< span > 06 </ span ></ li > </s> ▁< li >< span > 07 </ span ></ li > </s> ▁< li >< span > 08 </ span ></ li > </s> </s> ▁</ ul > </s>\n",
      "----------------------------------------------------------------------------------------------------\n",
      "352 tokens\n",
      "----------------------------------------------------------------------------------------------------\n",
      "▁We ▁a im ed ▁to ▁ev al u ate ▁the ▁effect ▁of ▁sleep ▁qu ality ▁on ▁mem ory , ▁exec utive ▁function , ▁and ▁language ▁performance ▁in ▁pat ients ▁with ▁ref ract ory ▁foc al ▁ep ile ps y ▁and ▁contro lled ▁ep ile ps y ▁and ▁comp are ▁these </s> ▁with ▁health y ▁individual s . ▁We ▁pro s pect ively ▁en ro lled ▁3 7 ▁ad ol es cent ▁and ▁ad ult ▁pat ients ▁with ▁ref ract ory ▁foc al ▁ep ile ps y . </s> </s> ▁How ▁to ▁av oid ▁anti - cl ock wise ▁ro t ation ▁anim ation ▁when ▁res et ing ▁ro t ation ▁from ▁3 60 de g ▁to ▁0 ▁deg ? </s> </s> ▁I ▁am ▁creat ing ▁an ▁anim ation ▁that ▁looks ▁like ▁a ▁f anc y ▁whe el , ▁When ▁res et ting ▁ro t ation ▁from ▁3 60 de g ▁to ▁0 ▁deg , ▁It ▁anim ating ▁the ▁whe el ▁in ▁anti - cl ock wise ▁dire ction , ▁How ▁to ▁A v oid ▁this ? ? ? </s> ▁H T M L </s> ▁< ul ▁class = \" c m \" > </s> ▁< li > < sp an > 0 1 < / sp an > < / li > </s> ▁< li > < sp an > 0 2 < / sp an > < / li > </s> ▁< li > < sp an > 0 3 < / sp an > < / li > </s> ▁< li > < sp an > 0 4 < / sp an > < / li > </s> ▁< li > < sp an > 0 5 < / sp an > < / li > </s> ▁< li > < sp an > 0 6 < / sp an > < / li > </s> ▁< li > < sp an > 0 7 < / sp an > < / li > </s> ▁< li > < sp an > 0 8 < / sp an > < / li > </s> </s> ▁< / ul > </s>\n",
      "----------------------------------------------------------------------------------------------------\n",
      "326 tokens\n",
      "----------------------------------------------------------------------------------------------------\n",
      "▁We ▁aim ed ▁to ▁eval uate ▁the ▁effect ▁of ▁sleep ▁quality ▁on ▁memory , ▁executive ▁function , ▁and ▁language ▁performance ▁in ▁patients ▁with ▁ref ract ory ▁foc al ▁ep ile ps y ▁and ▁contro lled ▁ep ile ps y ▁and ▁comp are ▁these </s> ▁with ▁healthy ▁individuals . ▁We ▁prospect ively ▁en ro lled ▁37 ▁ad oles cent ▁and ▁adult ▁patients ▁with ▁ref ract ory ▁foc al ▁ep ile ps y . </s> </s> ▁How ▁to ▁avoid ▁anti - cl ock wise ▁rot ation ▁anim ation ▁when ▁res et ing ▁rot ation ▁from ▁3 60 de g ▁to ▁0 ▁deg ? </s> </s> ▁I ▁am ▁creating ▁an ▁anim ation ▁that ▁looks ▁like ▁a ▁f ancy ▁wheel , ▁When ▁res et ting ▁rot ation ▁from ▁3 60 de g ▁to ▁0 ▁deg , ▁It ▁anim ating ▁the ▁wheel ▁in ▁anti - cl ock wise ▁direction , ▁How ▁to ▁Av oid ▁this ? ? ? </s> ▁H T M L </s> ▁< ul ▁class =\" c m \" > </s> ▁< li > < sp an > 0 1 < / sp an > < / li > </s> ▁< li > < sp an > 0 2 < / sp an > < / li > </s> ▁< li > < sp an > 0 3 < / sp an > < / li > </s> ▁< li > < sp an > 0 4 < / sp an > < / li > </s> ▁< li > < sp an > 0 5 < / sp an > < / li > </s> ▁< li > < sp an > 0 6 < / sp an > < / li > </s> ▁< li > < sp an > 0 7 < / sp an > < / li > </s> ▁< li > < sp an > 0 8 < / sp an > < / li > </s> </s> ▁< / ul > </s>\n",
      "----------------------------------------------------------------------------------------------------\n",
      "280 tokens\n",
      "----------------------------------------------------------------------------------------------------\n",
      "▁We ▁aimed ▁to ▁eval uate ▁the ▁effect ▁of ▁sleep ▁quality ▁on ▁memory , ▁executive ▁function , ▁and ▁language ▁performance ▁in ▁patients ▁with ▁ref ract ory ▁foc al ▁ep ile ps y ▁and ▁controlled ▁ep ile ps y ▁and ▁compare ▁these </s> ▁with ▁healthy ▁individuals . ▁We ▁prospect ively ▁en rolled ▁37 ▁adoles cent ▁and ▁adult ▁patients ▁with ▁ref ract ory ▁foc al ▁ep ile ps y . </s> </s> ▁How ▁to ▁avoid ▁anti - clock wise ▁rot ation ▁animation ▁when ▁res et ing ▁rot ation ▁from ▁3 60 de g ▁to ▁0 ▁deg ? </s> </s> ▁I ▁am ▁creating ▁an ▁animation ▁that ▁looks ▁like ▁a ▁fancy ▁wheel , ▁When ▁res et ting ▁rot ation ▁from ▁3 60 de g ▁to ▁0 ▁deg , ▁It ▁anim ating ▁the ▁wheel ▁in ▁anti - clock wise ▁direction , ▁How ▁to ▁Av oid ▁this ? ? ? </s> ▁H TM L </s> ▁< ul ▁class =\" cm \" > </s> ▁< li > < span > 0 1 </ span > </ li > </s> ▁< li > < span > 0 2 </ span > </ li > </s> ▁< li > < span > 0 3 </ span > </ li > </s> ▁< li > < span > 0 4 </ span > </ li > </s> ▁< li > < span > 05 </ span > </ li > </s> ▁< li > < span > 0 6 </ span > </ li > </s> ▁< li > < span > 0 7 </ span > </ li > </s> ▁< li > < span > 08 </ span > </ li > </s> </s> ▁< / ul > </s>\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "from itertools import chain\n",
    "import sentencepiece as spm\n",
    "from tokenizers import SentencePieceUnigramTokenizer, Tokenizer\n",
    "\n",
    "text_sample = \"\"\"We aimed to evaluate the effect of sleep quality on memory, executive function, and language performance in patients with refractory focal epilepsy and controlled epilepsy and compare these\n",
    " with healthy individuals. We prospectively enrolled 37 adolescent and adult patients with refractory focal epilepsy.\n",
    "\n",
    "How to avoid anti-clockwise rotation animation when reseting rotation from 360deg to 0 deg?\n",
    "\n",
    "I am creating an animation that looks like a fancy wheel, When resetting rotation from 360deg to 0 deg, It animating the wheel in anti-clockwise direction, How to Avoid this???\n",
    "HTML\n",
    "<ul class=\"cm\">\n",
    "  <li><span>01</span></li>\n",
    "  <li><span>02</span></li>\n",
    "  <li><span>03</span></li>\n",
    "  <li><span>04</span></li>\n",
    "  <li><span>05</span></li>\n",
    "  <li><span>06</span></li>\n",
    "  <li><span>07</span></li>\n",
    "  <li><span>08</span></li>\n",
    "\n",
    "</ul>\n",
    "\"\"\"\n",
    "\n",
    "print(\"Split on whitespace\", len(text_sample.split()), \"tokens\")\n",
    "\n",
    "for t in (4, 8, 16, 32):\n",
    "    print(\"-\"*100)\n",
    "    sp = spm.SentencePieceProcessor(model_file=f'spmodels/pile_{t}k.model', add_eos=True)\n",
    "    tokenized = sp.encode(text_sample.splitlines(), out_type=str)\n",
    "    tokenized = list(chain(*tokenized))\n",
    "    print(len(tokenized), \"tokens\")\n",
    "    print(\"-\" *100)\n",
    "    print(\" \".join(tokenized))\n",
    "\n",
    "for t in (4, 8, 16):\n",
    "    print(\"-\"*100)\n",
    "    sp = spm.SentencePieceProcessor(model_file=f'spbpemodels/pile_bpe_{t}k.model', add_eos=True)\n",
    "    tokenized = sp.encode(text_sample.splitlines(), out_type=str)\n",
    "    tokenized = list(chain(*tokenized))\n",
    "    print(len(tokenized), \"tokens\")\n",
    "    print(\"-\" *100)\n",
    "    print(\" \".join(tokenized))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "Loading 4k_model\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Loading 8k_model\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Loading 16k_model\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Loading 32k_model\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Save tokenizers into json\"\"\"\n",
    "\n",
    "from tokenizers import SentencePieceUnigramTokenizer\n",
    "\n",
    "for t in (4, 8, 16, 32):\n",
    "    print(\"-\"*100)\n",
    "    print(f\"Loading {t}k_model\")\n",
    "    tokenizer = SentencePieceUnigramTokenizer.from_spm(f\"spmodels/pile_{t}k.model\")\n",
    "    tokenizer.save(f\"tokenizers/pile_{t}.json\", pretty=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "Loading tokenizers 4k_model\n",
      "34051862 tokens\n",
      "processed in  17 secs\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Loading tokenizers 8k_model\n",
      "30989028 tokens\n",
      "processed in  20 secs\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Loading tokenizers 16k_model\n",
      "26695247 tokens\n",
      "processed in  19 secs\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Loading tokenizers 32k_model\n",
      "24625391 tokens\n",
      "processed in  18 secs\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Loading spm 4k_model\n",
      "34051862 tokens\n",
      "processed in  27 secs\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Loading spm 8k_model\n",
      "30989028 tokens\n",
      "processed in  28 secs\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Loading spm 16k_model\n",
      "26695247 tokens\n",
      "processed in  25 secs\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Loading spm 32k_model\n",
      "24625388 tokens\n",
      "processed in  25 secs\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import sentencepiece as spm\n",
    "from tokenizers import Tokenizer\n",
    "\n",
    "text_sample = open(\"../data/enwik8/train.txt.raw\").read().splitlines()\n",
    "\n",
    "for t in (4, 8, 16, 32):\n",
    "    print(\"-\"*100)\n",
    "    print(f\"Loading tokenizers {t}k_model\")\n",
    "    tokenizer = Tokenizer.from_file(f\"tokenizers/pile_{t}.json\")\n",
    "    \n",
    "    starttime = time.time()\n",
    "    tokenized = tokenizer.encode_batch(text_sample)\n",
    "    \n",
    "    print(sum(len(x) for x in tokenized), \"tokens\")\n",
    "    print(\"processed in \", int(time.time() - starttime), \"secs\")\n",
    "    print(\"-\" *100)\n",
    "    \n",
    "for t in (4, 8, 16, 32):\n",
    "    print(\"-\"*100)\n",
    "    print(f\"Loading spm {t}k_model\")\n",
    "    sp = spm.SentencePieceProcessor(model_file=f'spmodels/pile_{t}k.model')\n",
    "\n",
    "    starttime = time.time()\n",
    "    sptokenized = sp.encode(text_sample)\n",
    "    \n",
    "    print(sum(len(x) for x in sptokenized), \"tokens\")\n",
    "    print(\"processed in \", int(time.time() - starttime), \"secs\")\n",
    "    print(\"-\" *100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "Loading spm 4k_model\n",
      "35483362 tokens\n",
      "processed in  53 secs\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Loading spm 8k_model\n",
      "31882148 tokens\n",
      "processed in  53 secs\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Loading spm 16k_model\n",
      "29134198 tokens\n",
      "processed in  55 secs\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Loading spm 32k_model\n",
      "26696255 tokens\n",
      "processed in  57 secs\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import sentencepiece as spm\n",
    "from tokenizers import Tokenizer\n",
    "\n",
    "text_sample = open(\"../data/enwik8/train.txt.raw\").read().splitlines()\n",
    "\n",
    "for t in (4, 8, 16, 32):\n",
    "    print(\"-\"*100)\n",
    "    print(f\"Loading spm {t}k_model\")\n",
    "    sp = spm.SentencePieceProcessor(model_file=f'spbpemodels/pile_bpe_{t}k.model')\n",
    "\n",
    "    starttime = time.time()\n",
    "    sptokenized = sp.encode(text_sample)\n",
    "    \n",
    "    print(sum(len(x) for x in sptokenized), \"tokens\")\n",
    "    print(\"processed in \", int(time.time() - starttime), \"secs\")\n",
    "    print(\"-\" *100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "Loading bbpe 4k_model\n",
      "Saving ../bin/bbpe/4k/enwiki.train.pt\n",
      "torch.Size([35494562])\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Loading bbpe 4k_model\n",
      "Saving ../bin/bbpe/4k/enwiki.valid.pt\n",
      "torch.Size([1965518])\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Loading bbpe 4k_model\n",
      "Saving ../bin/bbpe/4k/enwiki.test.pt\n",
      "torch.Size([1991092])\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Loading bbpe 8k_model\n",
      "Saving ../bin/bbpe/8k/enwiki.train.pt\n",
      "torch.Size([32052256])\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Loading bbpe 8k_model\n",
      "Saving ../bin/bbpe/8k/enwiki.valid.pt\n",
      "torch.Size([1769899])\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Loading bbpe 8k_model\n",
      "Saving ../bin/bbpe/8k/enwiki.test.pt\n",
      "torch.Size([1804016])\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Loading bbpe 16k_model\n",
      "Saving ../bin/bbpe/16k/enwiki.train.pt\n",
      "torch.Size([29135826])\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Loading bbpe 16k_model\n",
      "Saving ../bin/bbpe/16k/enwiki.valid.pt\n",
      "torch.Size([1608686])\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Loading bbpe 16k_model\n",
      "Saving ../bin/bbpe/16k/enwiki.test.pt\n",
      "torch.Size([1636220])\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Loading bbpe 32k_model\n",
      "Saving ../bin/bbpe/32k/enwiki.train.pt\n",
      "torch.Size([27009453])\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Loading bbpe 32k_model\n",
      "Saving ../bin/bbpe/32k/enwiki.valid.pt\n",
      "torch.Size([1494737])\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Loading bbpe 32k_model\n",
      "Saving ../bin/bbpe/32k/enwiki.test.pt\n",
      "torch.Size([1525053])\n"
     ]
    }
   ],
   "source": [
    "from tokenizers import Tokenizer\n",
    "import torch\n",
    "from itertools import chain\n",
    "\n",
    "train = [ l for l in open(\"../data/enwik8/train.txt.raw\").read().splitlines() if l.strip() ]\n",
    "test = [ l for l in open(\"../data/enwik8/test.txt.raw\").read().splitlines() if l.strip() ]\n",
    "valid = [ l for l in open(\"../data/enwik8/valid.txt.raw\").read().splitlines() if l.strip() ]\n",
    "\n",
    "for t in (4, 8, 16, 32):\n",
    "\n",
    "    for s, v in ((\"train\", train), (\"valid\", valid), (\"test\", test)):\n",
    "        print(\"-\"*100)\n",
    "        print(f\"Loading bbpe {t}k_model\")\n",
    "\n",
    "        tokenizer = Tokenizer.from_file(f'bbpe/bbpe.{t}k.tokenizer.json')\n",
    "\n",
    "        tokenizer.no_padding()\n",
    "        tokenizer.post_processor = TemplateProcessing(\n",
    "            single=\"$0 </s>\",\n",
    "            special_tokens=[(\"</s>\", 2)],\n",
    "        )\n",
    "\n",
    "        tokenized = tokenizer.encode_batch(v, add_special_tokens=False)\n",
    "        tokenized = list(chain(*[ x.ids for x in tokenized]))\n",
    "        tokenized = torch.ShortTensor(tokenized)\n",
    "        torch.save(tokenized, f\"../bin/bbpe/{t}k/enwiki.{s}.pt\")\n",
    "        print(\"Saving\", f\"../bin/bbpe/{t}k/enwiki.{s}.pt\")\n",
    "        print(tokenized.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
